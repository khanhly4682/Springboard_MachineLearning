{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Risk Analyze.\n",
    "__Objective:__\n",
    " Use historical loan application data to predict if an application will be able to repay a loan.\n",
    " \n",
    "#### Problem statement:\n",
    "Building a model to predict how capable each applicant is of repaying a loan.\n",
    "\n",
    "#### Performance metric:\n",
    "In this problem, the data is imbalanced. So we can’t use accuracy as a error metric. When data is imbalanced we can use Log loss, F1-score and AUC. Here we are sticking to AUC which can handle imbalanced datasets.\n",
    " This is a standard supervised classification task:\n",
    "\n",
    "__Supervised__: The labels are included in the training data and the goal is to train a model to learn to predict the labels from the features.<br>\n",
    "__Classification__: The label is a binary variable, \n",
    "- 0 (will repay loan on time), \n",
    "- 1 (will have difficulty repaying loan)<br>\n",
    "\n",
    "#### Data Description\n",
    "\n",
    "Data\n",
    "The applicant data and previous applicationsis provided by Home Credit, with credits data from Credit Bureau.\n",
    "https://www.kaggle.com/c/home-credit-default-risk/data\n",
    "\n",
    "There are 7 different sources of data:\n",
    "\n",
    "- *application_train/application_test*: the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature SK_ID_CURR. The training application data comes with the TARGET indicating 0: the loan was repaid or 1: the loan was not repaid.\n",
    "- *bureau*: data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits.\n",
    "- *bureau_balance*: monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length.\n",
    "- *previous_application*: previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature SK_ID_PREV.\n",
    "- *POS_CASH_BALANCE*: monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows.\n",
    "_*credit_card_balance*: monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows.\n",
    "-*installments_payment*: payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDIT_AMT_RECEIVABLE_PRINCIPAL</th>\n",
       "      <th>CREDIT_AMT_RECIVABLE</th>\n",
       "      <th>CREDIT_AMT_TOTAL_RECEIVABLE</th>\n",
       "      <th>CREDIT_CNT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>CREDIT_CNT_DRAWINGS_CURRENT</th>\n",
       "      <th>CREDIT_CNT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>CREDIT_CNT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>CREDIT_CNT_INSTALMENT_MATURE_CUM</th>\n",
       "      <th>CREDIT_SK_DPD</th>\n",
       "      <th>CREDIT_SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "         ...          CREDIT_AMT_RECEIVABLE_PRINCIPAL CREDIT_AMT_RECIVABLE  \\\n",
       "0        ...                                      0.0                  0.0   \n",
       "1        ...                                      0.0                  0.0   \n",
       "2        ...                                      0.0                  0.0   \n",
       "3        ...                                      0.0                  0.0   \n",
       "4        ...                                      0.0                  0.0   \n",
       "\n",
       "  CREDIT_AMT_TOTAL_RECEIVABLE CREDIT_CNT_DRAWINGS_ATM_CURRENT  \\\n",
       "0                         0.0                             0.0   \n",
       "1                         0.0                             0.0   \n",
       "2                         0.0                             0.0   \n",
       "3                         0.0                             0.0   \n",
       "4                         0.0                             0.0   \n",
       "\n",
       "  CREDIT_CNT_DRAWINGS_CURRENT CREDIT_CNT_DRAWINGS_OTHER_CURRENT  \\\n",
       "0                         0.0                               0.0   \n",
       "1                         0.0                               0.0   \n",
       "2                         0.0                               0.0   \n",
       "3                         0.0                               0.0   \n",
       "4                         0.0                               0.0   \n",
       "\n",
       "   CREDIT_CNT_DRAWINGS_POS_CURRENT  CREDIT_CNT_INSTALMENT_MATURE_CUM  \\\n",
       "0                              0.0                               0.0   \n",
       "1                              0.0                               0.0   \n",
       "2                              0.0                               0.0   \n",
       "3                              0.0                               0.0   \n",
       "4                              0.0                               0.0   \n",
       "\n",
       "   CREDIT_SK_DPD  CREDIT_SK_DPD_DEF  \n",
       "0            0.0                0.0  \n",
       "1            0.0                0.0  \n",
       "2            0.0                0.0  \n",
       "3            0.0                0.0  \n",
       "4            0.0                0.0  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data we already cleaned in the previous step.\n",
    "df = pd.read_csv('D:\\\\70. Study\\\\00 Data Science Springboard\\\\02-Project Capstone 1\\\\data\\\\application_training.csv') # rename from 'cleaned_csv'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 199 entries, SK_ID_CURR to CREDIT_SK_DPD_DEF\n",
      "dtypes: float64(141), int64(42), object(16)\n",
      "memory usage: 466.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 199)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Description of data:\n",
    "1. The data contains 307,509 rows and 198 columns.\n",
    "2. Each row has unique id 'SK_ID_CURR' \n",
    "3. Output label is 'TARGET' column.\n",
    "- If TARGET = 0: the loan was repaid.\n",
    "- If TARGET = 1: the loan was not repaid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation:\n",
    "### Feature Engineering of Application data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we have an overview of the dataset. There is still some essential data preprocessing needed before we proceed towards building our machine learning model. We are going to perform the preprocessing steps including:\n",
    "\n",
    "1. Handle the missing data\n",
    "2. Convert the non-numerical (categorical) data into numeric.\n",
    "3. Remove outlier.\n",
    "4. Split the data into training and test sets.\n",
    "5. Scale the feature values to a uniform range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Handle the missing data.\n",
    "Missing values are values that are not recorded during data collection. They can be mostly not provided or left out due errors. Let's check the missing data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FONDKAPREMONT_MODE               210295\n",
       "WALLSMATERIAL_MODE               156341\n",
       "HOUSETYPE_MODE                   154297\n",
       "EMERGENCYSTATE_MODE              145755\n",
       "OCCUPATION_TYPE                   96391\n",
       "NAME_TYPE_SUITE                    1292\n",
       "LIVINGAREA_AVG                        0\n",
       "COMMONAREA_MODE                       0\n",
       "NONLIVINGAPARTMENTS_MODE              0\n",
       "LIVINGAREA_MODE                       0\n",
       "LIVINGAPARTMENTS_MODE                 0\n",
       "LANDAREA_MODE                         0\n",
       "FLOORSMIN_MODE                        0\n",
       "FLOORSMAX_MODE                        0\n",
       "ENTRANCES_MODE                        0\n",
       "ELEVATORS_MODE                        0\n",
       "YEARS_BUILD_MODE                      0\n",
       "NONLIVINGAPARTMENTS_AVG               0\n",
       "YEARS_BEGINEXPLUATATION_MODE          0\n",
       "BASEMENTAREA_MODE                     0\n",
       "NONLIVINGAREA_MODE                    0\n",
       "FLOORSMIN_AVG                         0\n",
       "APARTMENTS_MODE                       0\n",
       "LANDAREA_AVG                          0\n",
       "LIVINGAPARTMENTS_AVG                  0\n",
       "NONLIVINGAREA_AVG                     0\n",
       "CREDIT_SK_DPD_DEF                     0\n",
       "YEARS_BEGINEXPLUATATION_MEDI          0\n",
       "APARTMENTS_MEDI                       0\n",
       "BASEMENTAREA_MEDI                     0\n",
       "                                  ...  \n",
       "FLAG_DOCUMENT_10                      0\n",
       "FLAG_DOCUMENT_9                       0\n",
       "FLAG_DOCUMENT_8                       0\n",
       "FLAG_DOCUMENT_7                       0\n",
       "BUREAU_DAYS_CREDIT                    0\n",
       "BUREAU_DAYS_CREDIT_ENDDATE            0\n",
       "PREV_CNT_PAYMENT                      0\n",
       "BUREAU_DAYS_ENDDATE_FACT              0\n",
       "PREV_SELLERPLACE_AREA                 0\n",
       "PREV_DAYS_DECISION                    0\n",
       "PREV_RATE_INTEREST_PRIVILEGED         0\n",
       "PREV_RATE_INTEREST_PRIMARY            0\n",
       "PREV_RATE_DOWN_PAYMENT                0\n",
       "PREV_NFLAG_LAST_APPL_IN_DAY           0\n",
       "PREV_HOUR_APPR_PROCESS_START          0\n",
       "PREV_AMT_GOODS_PRICE                  0\n",
       "PREV_AMT_DOWN_PAYMENT                 0\n",
       "PREV_AMT_CREDIT                       0\n",
       "PREV_AMT_APPLICATION                  0\n",
       "PREV_AMT_ANNUITY                      0\n",
       "PREV_APP_COUNT                        0\n",
       "BUREAU_AMT_ANNUITY                    0\n",
       "BUREAU_DAYS_CREDIT_UPDATE             0\n",
       "BUREAU_AMT_CREDIT_SUM_OVERDUE         0\n",
       "BUREAU_AMT_CREDIT_SUM_LIMIT           0\n",
       "BUREAU_AMT_CREDIT_SUM_DEBT            0\n",
       "BUREAU_AMT_CREDIT_SUM                 0\n",
       "BUREAU_CNT_CREDIT_PROLONG             0\n",
       "BUREAU_AMT_CREDIT_MAX_OVERDUE         0\n",
       "SK_ID_CURR                            0\n",
       "Length: 199, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of missing columns:\n",
      "--NAME_TYPE_SUITE: object\n",
      "--OCCUPATION_TYPE: object\n",
      "--EMERGENCYSTATE_MODE: object\n",
      "--WALLSMATERIAL_MODE: object\n",
      "--FONDKAPREMONT_MODE: object\n"
     ]
    }
   ],
   "source": [
    "# Missing values for NAME_TYPE_SUITE\n",
    "print('Type of missing columns:')\n",
    "print('--NAME_TYPE_SUITE:', df.NAME_TYPE_SUITE.dtype)\n",
    "print('--OCCUPATION_TYPE:', df.OCCUPATION_TYPE.dtype)\n",
    "print('--EMERGENCYSTATE_MODE:', df.EMERGENCYSTATE_MODE.dtype)\n",
    "print('--WALLSMATERIAL_MODE:', df.WALLSMATERIAL_MODE.dtype)\n",
    "print('--FONDKAPREMONT_MODE:', df.FONDKAPREMONT_MODE.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have NAME_TYPE_SUITE, OCCUPATION_TYPE, EMERGENCYSTATE_MODE, WALLSMATERIAL_MODE, FONDKAPREMONT_MODE  are categorical data. So we will fill out the missing value as NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         reg oper account\n",
       "1         reg oper account\n",
       "2                       NA\n",
       "3                       NA\n",
       "4                       NA\n",
       "5                       NA\n",
       "6                       NA\n",
       "7                       NA\n",
       "8                       NA\n",
       "9                       NA\n",
       "10                      NA\n",
       "11                      NA\n",
       "12        reg oper account\n",
       "13        reg oper account\n",
       "14        reg oper account\n",
       "15                      NA\n",
       "16                      NA\n",
       "17                      NA\n",
       "18        reg oper account\n",
       "19                      NA\n",
       "20        reg oper account\n",
       "21                      NA\n",
       "22        reg oper account\n",
       "23        org spec account\n",
       "24        reg oper account\n",
       "25        reg oper account\n",
       "26                      NA\n",
       "27                      NA\n",
       "28                      NA\n",
       "29        reg oper account\n",
       "                ...       \n",
       "307481                  NA\n",
       "307482       not specified\n",
       "307483    reg oper account\n",
       "307484                  NA\n",
       "307485                  NA\n",
       "307486                  NA\n",
       "307487                  NA\n",
       "307488                  NA\n",
       "307489    reg oper account\n",
       "307490                  NA\n",
       "307491                  NA\n",
       "307492                  NA\n",
       "307493                  NA\n",
       "307494                  NA\n",
       "307495    org spec account\n",
       "307496                  NA\n",
       "307497                  NA\n",
       "307498                  NA\n",
       "307499                  NA\n",
       "307500                  NA\n",
       "307501                  NA\n",
       "307502                  NA\n",
       "307503                  NA\n",
       "307504                  NA\n",
       "307505    reg oper account\n",
       "307506    reg oper account\n",
       "307507    reg oper account\n",
       "307508    reg oper account\n",
       "307509                  NA\n",
       "307510                  NA\n",
       "Name: FONDKAPREMONT_MODE, Length: 307511, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.NAME_TYPE_SUITE.fillna('NA')\n",
    "df.OCCUPATION_TYPE.fillna('NA')\n",
    "df.EMERGENCYSTATE_MODE.fillna('NA')\n",
    "df.WALLSMATERIAL_MODE.fillna('NA')\n",
    "df.FONDKAPREMONT_MODE.fillna('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. Feature Engineering on Categorical Data\n",
    "Typically, feature engineering involves transformation of these categorical values into numerical labels and then applying some encoding scheme on these values.\n",
    "\n",
    "Let look at the number of unique entries in each categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME_CONTRACT_TYPE',\n",
       " 'CODE_GENDER',\n",
       " 'FLAG_OWN_CAR',\n",
       " 'FLAG_OWN_REALTY',\n",
       " 'NAME_TYPE_SUITE',\n",
       " 'NAME_INCOME_TYPE',\n",
       " 'NAME_EDUCATION_TYPE',\n",
       " 'NAME_FAMILY_STATUS',\n",
       " 'NAME_HOUSING_TYPE',\n",
       " 'OCCUPATION_TYPE',\n",
       " 'WEEKDAY_APPR_PROCESS_START',\n",
       " 'ORGANIZATION_TYPE',\n",
       " 'FONDKAPREMONT_MODE',\n",
       " 'HOUSETYPE_MODE',\n",
       " 'WALLSMATERIAL_MODE',\n",
       " 'EMERGENCYSTATE_MODE']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all categorical columns.\n",
    "categoricals = df.select_dtypes('object')\n",
    "categoricals.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy variables\n",
    "Considering we have the numeric representation of any categorical attribute with m labels (after transformation),get_dummies() will encode or transform the attribute into m binary features which can only contain a value of 1 or 0. Each observation in the categorical feature is thus converted into a vector of size m with only one of the values as 1 (indicating it as active)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert categorical variable into dummy variables.\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove outlier\n",
    "\n",
    "An outlier is an observation point that is distant from other observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    307511.000000\n",
       "mean        174.835742\n",
       "std         387.056895\n",
       "min         -49.073973\n",
       "25%          -7.561644\n",
       "50%          -3.323288\n",
       "75%          -0.791781\n",
       "max        1000.665753\n",
       "Name: DAYS_EMPLOYED, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The maxixum days of employed 'DAYS_EMPLOYED' is 1000 years. \n",
    "# We will remove that outlier so it will not affect the performance of the model.\n",
    "(df['DAYS_EMPLOYED']/365).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df['DAYS_EMPLOYED'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365243"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the max of days_employed.\n",
    "max(df['DAYS_EMPLOYED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the rows where DAYS_EMPLOYED = 1000 years.\n",
    "df.drop(df[ df['DAYS_EMPLOYED'] == max(df['DAYS_EMPLOYED'])].index , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Splitting data into training and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create X and y dataset.\n",
    "# Drop the target from the data.\n",
    "if 'TARGET' in df:\n",
    "    X = df.drop(columns='TARGET')\n",
    "else:\n",
    "    X = df.copy()\n",
    "\n",
    "# Get test set.\n",
    "y = df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 201709\n",
      "X_test 50428\n",
      "y_train 201709\n",
      "y_test 50428\n"
     ]
    }
   ],
   "source": [
    "print('X_train:',len(X_train))\n",
    "print('X_test', len(X_test))\n",
    "print('y_train', len(y_train))\n",
    "print('y_test', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model implementation\n",
    "\n",
    "We will implement some machine learning algorithms and evaluate performance of the algorithms to find which one is the best for the data.\n",
    "The algorithms we implements include:\n",
    "\n",
    "* Logistic Regression \n",
    "* KNN\n",
    "* Random Forest\n",
    "\n",
    "#### 1. Logistic Regression.\n",
    "Logistic Regression is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). \n",
    "\n",
    "For a binary regression, the factor level 1 of the dependent variable should represent the desired outcome. In here, 1 mean customers who have risk of being able to repay the loan. 0 means customers can pay loan.\n",
    "And the important thing here is we want to know who cannot repay the loan, it means we care more about classification 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Test] Accuracy score (y_predict_test, ytestlr): 0.915205838026\n",
      "\n",
      "\n",
      "[Training] Accuracy score: (ylr, y_predict_training) 0.912507622367\n"
     ]
    }
   ],
   "source": [
    "# Create Logistic Regression model.\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "# Make predict the test set\n",
    "y_predict_test = lr.predict(X_test)\n",
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score (y_predict_test, ytestlr):\",accuracy_score(y_predict_test, y_test))\n",
    "\n",
    "# the training score\n",
    "y_predict_training = lr.predict(X_train)\n",
    "print(\"\\n\")\n",
    "print(\"[Training] Accuracy score: (ylr, y_predict_training)\",accuracy_score(y_train, y_predict_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     46180\n",
      "           1       0.06      0.00      0.00      4248\n",
      "\n",
      "    accuracy                           0.92     50428\n",
      "   macro avg       0.49      0.50      0.48     50428\n",
      "weighted avg       0.84      0.92      0.88     50428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for predicting test set.\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46150    30]\n",
      " [ 4246     2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "1. Class 1 have very low precision (0.06) and recall is 0. It means the model could not detect any person that does not have ability to pay the loan. This is because of the samples for class 1 is 1/10 compared with the number of samples for class 0 (people who pay the loan).\n",
    "2. So, we have to do resampling of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "- The imbalanced datasets causes a skewness in the data distribution, create the minority class and the majority class. The bias in the data cause the machine learning model ignore the minority class. \n",
    "\n",
    "To address the problem of class imbalance, we will randomly resample the dataset using undersampling. Undersampling means to delete examples from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 230302, 1: 21835})\n",
      "Counter({0: 21835, 1: 21835})\n"
     ]
    }
   ],
   "source": [
    "#define the undersampling method\n",
    "undersample = NearMiss(version=1,n_neighbors=3)\n",
    "\n",
    "print(Counter(y))\n",
    "\n",
    "# transform the dataset\n",
    "X1, y1 = undersample.fit_resample(X,y) \n",
    "\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y1)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after resampling, we have dataset for 43670 examples in which both class 1 and 0 have the same number of examples 21835. We will rerun the logistic regression model on the new resampling dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Test] Accuracy score (y_predict_test, ytestlr): 0.85688115411\n",
      "\n",
      "\n",
      "[Training] Accuracy score: (ylr, y_predict_training) 0.863579116098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86      4334\n",
      "           1       0.91      0.80      0.85      4400\n",
      "\n",
      "    accuracy                           0.86      8734\n",
      "   macro avg       0.86      0.86      0.86      8734\n",
      "weighted avg       0.86      0.86      0.86      8734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "def log_regression(X,y):\n",
    "    # Create training, test set.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    # Create Logistic Regression model.\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    # Fit the model\n",
    "    lr.fit(X_train,y_train)\n",
    "\n",
    "    # Make predict the test set\n",
    "    y_predict_test = lr.predict(X_test)\n",
    "    print(\"\\n\")\n",
    "    print(\"[Test] Accuracy score (y_predict_test, ytestlr):\",accuracy_score(y_predict_test, y_test))\n",
    "\n",
    "    # the training score\n",
    "    y_predict_training = lr.predict(X_train)\n",
    "    print(\"\\n\")\n",
    "    print(\"[Training] Accuracy score: (ylr, y_predict_training)\",accuracy_score(y_train, y_predict_training))\n",
    "    print(classification_report(y_test,y_predict_test ))\n",
    "    \n",
    "# Run logistic regression using resampling datasets X1, y1.\n",
    "log_regression(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796427753607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Cross validation.\n",
    "\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x.iloc[train], y.iloc[train]) # fit\n",
    "        result += score_func(clf.predict(x.iloc[test]), y.iloc[test]) # evaluate score function on held-out data\n",
    "        \n",
    "    return result / nfold # average\n",
    "\n",
    "# Using cv_score function for basic logistic regression without regularization.\n",
    "reg = LogisticRegression()\n",
    "score = cv_score(reg, X1, y1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch\n",
    "GridSearchCV():\n",
    "* Grid search builds a model for every combination of hyperparameters specified and evaluates each model\n",
    "* Exhaustive search over specified parameter values for an estimator.\n",
    "* GridSearchCV lets you combine an estimator with a grid search preamble to tune hyper-parameters. \n",
    "* The method picks the optimal parameter from the grid search and uses it with the estimator selected by the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We split resampling dataset into training and test sets.\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34936, 322)\n",
      "(8734, 322)\n",
      "(34936,)\n",
      "(8734,)\n",
      "0    17507\n",
      "1    17429\n",
      "Name: TARGET, dtype: int64\n",
      "1    4406\n",
      "0    4328\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X1_train.shape)\n",
    "print(X1_test.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_test.shape)\n",
    "print(y1_train.value_counts())\n",
    "print(y1_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch best score:  0.845912525761\n",
      "GridSearch best estimator for C: LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Performance on test set:  0.852644836272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearch with the training data.\n",
    "grid = GridSearchCV(lr, cv=5, param_grid = {'C': [0.001, 0.1, 1, 10, 100]})\n",
    "grid.fit(X1, y1)\n",
    "print(\"GridSearch best score: \", grid.best_score_)\n",
    "print(\"GridSearch best estimator for C:\", grid.best_estimator_ )\n",
    "\n",
    "# Predict performance on test set.\n",
    "print(\"Performance on test set: \", grid.score(X1_test, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GridSearch best score:  0.845912525761\n",
    "* GridSearch best estimator for C: LogisticRegression(C=10)\n",
    "* Performance on test set:  0.852644836272"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k Nearest Neighbor algorithms\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(X_train,y_train)\n",
    "neigh.predict(X_test)\n",
    "knn_score = neigh.score(X_test,y_test)\n",
    "print('Knn accurary score:',knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_predict = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classification report for KNN.\n",
    "print(classification_report(y_test, knn_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### 4. Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "print('Random Forest classification:', rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classification report for KNN.\n",
    "rf_predict = rf.predict(X_test)\n",
    "print(classification_report(y_test, rf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
